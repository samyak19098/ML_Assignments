# -*- coding: utf-8 -*-
"""Q1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16Gxg4u305UhloS1_XVSFKyltF_yzC_EC
"""

import numpy as np
import pandas as pd
import seaborn
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import seaborn

np.random.seed(0)

def readData():
    ''' Used to read the data from the csv format file into a pandas dataframe
        return a pandas DataFrame
    '''
    data = pd.read_csv('../data/PRSA_data_2010.1.1-2014.12.31.csv')
    return data

def preprocess(data):
    ''' Preprocessing function
        Input : dataFrame of data
        Returns: dataFrame of preprocessed data
    '''
    
    data = data.drop('No', axis=1) #drop 'No' column
    # data.isna().sum()
    # data = data.dropna() #dropping rows with missing data
    data = data.fillna(0)
    #One-hot encoding the cbwd column
    data['cbwd_SE'] = np.where(data['cbwd'] == 'SE', 1, 0)
    data['cbwd_cv'] = np.where(data['cbwd'] == 'cv', 1, 0)
    data['cbwd_NW'] = np.where(data['cbwd'] == 'NW', 1, 0)
    data['cbwd_NE'] = np.where(data['cbwd'] == 'NE', 1, 0)
    data = data.drop('cbwd', axis=1)

    return data

def extractFeatureAndResult(data):
    ''' Used to split the dataframe into input(features data) and the outcome(output result data)
        Input: pandas dataframe object
        returns two splitted data object : a dataframe with the input(feature data) and a series with the output(result/outcome) data.
    '''
    featureData = data.drop(['month'], axis='columns')
    labelData = data['month']
    return featureData, labelData

# featureData = data.drop(['month'], axis=1)
# labelData = data['month']
# for feature in featureData.columns:
#     seaborn.displot(featureData[feature])
# seaborn.displot(featureData.columns)

def custom_split(data, test_size):
    ''' Used to split data into training and testing set
        Input: Dataframe data to split,
            test_size : a positive float value in range [0,1] representing ratio of test data size to the whole dataset
            Returns two dataframes corresponding to training and testing data along with four numpy arrays
            train_X - Training feature(input) data, test_X - Testing feature(input) data, 
            train_Y - Training result/output data, test_Y - Testing result/output data
        '''
    shuffled_data = (data.sample(frac=1)).copy() #shuffling the dataset
    train_size = 1 - test_size
    num_train_sample = int(round(train_size * shuffled_data.shape[0]))
    # print(shuffled_data.iloc[:3,:])
    train_set = shuffled_data.iloc[:num_train_sample, :]
    test_set = shuffled_data.iloc[num_train_sample:, :]
    train_X = np.array(train_set.drop(['month'], axis='columns'))
    train_Y = np.array(train_set['month'])
    test_X = np.array(test_set.drop(['month'], axis='columns'))
    test_Y = np.array(test_set['month'])

    return train_set, test_set, train_X, test_X, train_Y, test_Y

data = readData()
data.columns

# #used to check null columns
# null_rows = data.isna().any(axis=1).sum()
# column_wise_null = data.isnull().sum()
# print(f'No. of rows with missing data: {null_rows}')
# print(column_wise_null)

# #Correlation checking
# corr_data = data.drop('No', axis=1)
# data_corr = corr_data.corr()
# plt.figure(figsize=(10,5))
# seaborn.heatmap(data_corr, xticklabels=data_corr.columns.values, yticklabels=data_corr.columns.values, annot=True, cmap='Blues')
# plt.savefig('../plots/EDA/correlation.png', facecolor='w', bbox_inches='tight')
# plt.show()

# #Pairplots plotted here
# seaborn.pairplot(data=corr_data)
# plt.savefig(f'../plots/EDA/pairplot.png', facecolor='w', bbox_inches='tight')

# #Distribution plots
# features = list(data.columns)
# to_remove = ['No', 'month', 'year', 'hour', 'day']
# for feat in to_remove:
#     features.remove(feat)

# print(features)
# for feat in features:
#     seaborn.displot(data[feat])

#     if(feat == 'pm2.5'):
#         plt.savefig(f'../plots/EDA/displot_pm', facecolor='w', bbox_inches='tight')
#     else:
#         plt.savefig(f'../plots/EDA/displot_{feat}', facecolor='w', bbox_inches='tight')
#     # pass

# #boxplots plotted for visualizing outliers
# # features.remove('cbwd')
# for feat in features:
#     seaborn.boxplot(x=data[feat])
    
#     if(feat == 'pm2.5'):
#         plt.savefig(f'../plots/EDA/boxplot_pm', facecolor='w', bbox_inches='tight')
#     else:
#         plt.savefig(f'../plots/EDA/boxplot_{feat}', facecolor='w', bbox_inches='tight')
#     plt.show()

#preprocessing data and splitting the same
data = preprocess(data)
cols = data.columns
train_set, test_val_set, train_X, test_val_X, train_Y, test_val_Y = custom_split(data, 0.3)
test_set, val_set, test_X, val_X, test_Y, val_Y = custom_split(test_val_set, 0.5)

def calculateAccuracy(prediction_values, actual_values):
    ''' Calculates accuracy of a prediction
        Input : a linear numpy array of predicted values, Actual labels
        Output: Accuracy (on scale of 0 to 1).
    '''
    y_predict = prediction_values
    y_actual = actual_values
    total = y_actual.shape[0]
    matches = np.sum(y_predict == y_actual)
    accuracy = matches / total
    return accuracy

"""(A) Training using Gini index and Entropy"""

def Q1_a(x_train, y_train, x_test, y_test):
    
    criterions = ["gini", "entropy"]
    for cri in criterions:
        model_dt = DecisionTreeClassifier(criterion=cri, random_state=0) #creating model based on criteria
        model_dt.fit(x_train, y_train) #fitting model
        prediction = model_dt.predict(x_test) #finding predictions on test set
        accuracy = calculateAccuracy(prediction, y_test) #calculating accuracy for prediction
        print(f'Criterion: {cri} => Test Accuracy : {accuracy}')

Q1_a(train_X, train_Y, test_X, test_Y)

"""Criterion Entropy gives a higher accuracy. So we'll proceed with using that."""

def Q1_b(x_train, y_train, x_test, y_test,plot=False):
    depths = [2, 4, 8, 10, 15, 30]
    train_acc = []
    test_acc = []

    #iterate and consider one depth at a time, train the model with that depth keeping criteria as entropy and calculate training as well as testing accuracies over it.
    for dpth in depths:
        model_dt = DecisionTreeClassifier(criterion="entropy", max_depth=dpth)
        model_dt.fit(x_train, y_train)
        test_prediction = model_dt.predict(x_test)
        train_prediction = model_dt.predict(x_train)
        train_accuracy = calculateAccuracy(train_prediction, y_train)
        test_accuracy = calculateAccuracy(test_prediction, y_test)
        train_acc.append(train_accuracy)
        test_acc.append(test_accuracy)
        print(f'Depth: {dpth} \nTrain Accuracy: {train_accuracy}\nTest Accuracy: {test_accuracy}\n-------------X-------------')
        
    #plotting the training and testing accuracy
    if(plot == True):
        plt.plot(depths, train_acc, marker='o', color='blue')
        plt.xlabel('Maximum depth')
        plt.ylabel('Train Accuracy')
        plt.title("Train accuracy vs Maximum depth")
        # plt.savefig('../plots/Q1b/train_accuracy.png', facecolor='w', bbox_inches='tight')
        plt.show()

        plt.plot(depths, test_acc, marker='o', color='red')
        plt.xlabel('Maximum depth')
        plt.ylabel('Test Accuracy')
        plt.title("Test accuracy vs Maximum depth")
        # plt.savefig('../plots/Q1b/test_accuracy.png', facecolor='w', bbox_inches='tight')
        plt.show()
        
        plt.plot(depths, train_acc, marker='o', label='train-accuracy',color='blue')
        plt.legend(loc='best')
        plt.plot(depths, test_acc, marker='o', label='test-accuracy',color='red')
        plt.legend(loc='best')
        plt.xlabel('Maximum depth')
        plt.ylabel('Accuracy')
        plt.title("Accuracy vs Maximum depth")
        # plt.savefig('../plots/Q1b/combined_plot.png', facecolor='w', bbox_inches='tight')
        plt.show()

Q1_b(train_X, train_Y, test_X, test_Y, plot=True)

"""Q1 (C)"""

def createEnsemble(num_estimators=100, tree_max_depth=3):
    ''' Creates an ensemble of decision tree classifiers
        Parameters : number of estimators, maximum depth of decision tree to be taken
        Output: A list containing all the individual decision tree classfiers of that ensemble
    '''
    tree_estimators = []
    for i in range(num_estimators):
        model_dt = DecisionTreeClassifier(criterion="entropy", max_depth=tree_max_depth)
        tree_estimators.append(model_dt)
    return tree_estimators

def majorityVoting(model_predictions):
    ''' implements the majority voting for calculating the final output of the ensemble/forest of multiple decision tree classifiers.
        Input: A two dimensional numpy array with outputs of each decision tree in the ensemble over all samples.
        Output: A one dimensional array with output of the whole ensemble (forest) computed by majority voting
    '''
    final_prediction = [] #final predicitions for all samples
    for col in range(model_predictions.shape[1]):
        votings = {} #for each sample, it holds the votes given to each label predicted by the various stumps for the particular sample.
        for row in range(model_predictions.shape[0]):
            if(model_predictions[row][col] not in votings):
                votings[model_predictions[row][col]] = 1 #if current stump is the first one predicting this output, initialize the number of votes for this as 1
            else:
                votings[model_predictions[row][col]] += 1 #if other classifiers have already predicted this output, add 1 to the votes
        majority_element = max(zip(votings.values(), votings.keys()))[1] #take the output/label with maximum votes
        final_prediction.append(majority_element)
    return final_prediction

def Q1_c(train_set, x_train, y_train, x_test, y_test):

    decision_stumps = createEnsemble(num_estimators=100, tree_max_depth=3) #create the ensemble with 100 trees and maximum depth as 3
    model_predictions_test = []
    model_predictions_train = []

    for model in decision_stumps:
        random_train_sample = (train_set.sample(frac=0.5)).copy() #randomly select 50% of the training set
        x_train_subset = np.array(random_train_sample.drop(['month'], axis='columns')) #get train_X subset
        y_train_subset = np.array(random_train_sample['month']) #get train_Y subset
        model.fit(x_train_subset, y_train_subset) #fit the model
        prediction = model.predict(x_test) #predict results on test set for each model
        model_predictions_test.append(prediction) 
        prediction_train = model.predict(x_train)
        model_predictions_train.append(prediction_train)

    model_predictions_test = np.array(model_predictions_test)
    final_prediction_test = np.array(majorityVoting(model_predictions_test)) #final predictions is the majority voting of predictions of individual stumps for each sample.
    final_test_accuracy = calculateAccuracy(final_prediction_test, y_test) #calculate accuracy for testing set

    model_predictions_train = np.array(model_predictions_train)
    final_prediction_train = np.array(majorityVoting(model_predictions_train))
    final_train_accuracy = calculateAccuracy(final_prediction_train, y_train) #calculate accuracy for training set
    
    print(f'Test accuracy : {final_test_accuracy}')
    print(f'Train accuracy : {final_train_accuracy}')

Q1_c(train_set, train_X, train_Y, test_X, test_Y)

"""Q1(d) Tuning the stumps"""

def Q1_d(train_set, x_train, y_train, x_test, y_test, x_val, y_val, plot=False):
    '''Here we do three things,
        Varying the max_depth keeping the number of estimators as 100
        Varying the number of trees keeping the max_depth as 3
        Varying both max_depth and number of trees simultaneously
    '''
    depths = [4, 8, 10, 15, 20, 30]
    num_trees = [25, 50, 75, 100, 125, 150]

    train_acc_dpth = []
    test_acc_dpth = []
    val_acc_dpth = []

    # Varying the max-depth for num_trees = 100
    for dpth in depths:
        decision_stumps = createEnsemble(num_estimators=100, tree_max_depth=dpth) #create ensemble of 100 trees with max_depth in list depths
        model_predictions_test = []
        model_predictions_train = []
        model_predictions_val = []

        #iterating over each tree in the stump and finding predictions for all samples for each stump.
        for model in decision_stumps:

            random_train_sample = (train_set.sample(frac=0.5)).copy() #randomly select 50% of training data
            x_train_subset = np.array(random_train_sample.drop(['month'], axis='columns'))
            y_train_subset = np.array(random_train_sample['month'])
            model.fit(x_train_subset, y_train_subset)

            prediction = model.predict(x_test)
            model_predictions_test.append(prediction)

            prediction_train = model.predict(x_train)
            model_predictions_train.append(prediction_train)

            prediction_val = model.predict(x_val)
            model_predictions_val.append(prediction_val)

        model_predictions_test = np.array(model_predictions_test)
        final_prediction_test = np.array(majorityVoting(model_predictions_test)) #majority voting for predicting ouput over test set
        final_test_accuracy = calculateAccuracy(final_prediction_test, y_test) #calculating accuracy for test set predictions
        test_acc_dpth.append(final_test_accuracy)

        model_predictions_train = np.array(model_predictions_train)
        final_prediction_train = np.array(majorityVoting(model_predictions_train)) #majority voting for predicting ouput over train set
        final_train_accuracy = calculateAccuracy(final_prediction_train, y_train) #calculating accuracy for test set predictions
        train_acc_dpth.append(final_train_accuracy)

        model_predictions_val = np.array(model_predictions_val)
        final_prediction_val = np.array(majorityVoting(model_predictions_val)) #majority voting for predicting ouput over val set
        final_val_accuracy = calculateAccuracy(final_prediction_val, y_val) #calculating accuracy for test set predictions
        val_acc_dpth.append(final_val_accuracy)

        print(f'Depth: {dpth} \nTrain Accuracy: {final_train_accuracy}\nTest Accuracy: {final_test_accuracy}\nValidation Accuracy: {final_val_accuracy}\n-------------X-------------')
    
    #plotting the accuracy vs max_depth graph
    if(plot==True):
        plt.plot(depths, train_acc_dpth, marker='o', color='blue')
        plt.xlabel('Maximum depth')
        plt.ylabel('Train Accuracy')
        plt.title("Train accuracy vs Maximum depth")
        # plt.savefig('../plots/Q1d/depth_train_accuracy.png', facecolor='w', bbox_inches='tight')
        plt.show()

        plt.plot(depths, test_acc_dpth, marker='o', color='red')
        plt.xlabel('Maximum depth')
        plt.ylabel('Test Accuracy')
        plt.title("Test accuracy vs Maximum depth")
        # plt.savefig('../plots/Q1d/depth_test_accuracy.png', facecolor='w', bbox_inches='tight')
        plt.show()

        plt.plot(depths, val_acc_dpth, marker='o', color='yellow')
        plt.xlabel('Maximum depth')
        plt.ylabel('Val Accuracy')
        plt.title("Validation accuracy vs Maximum depth")
        # plt.savefig('../plots/Q1d/depth_val_accuracy.png', facecolor='w', bbox_inches='tight')
        plt.show()
        
        plt.plot(depths, train_acc_dpth, marker='o', label='train-accuracy',color='blue')
        plt.legend(loc='best')
        plt.plot(depths, test_acc_dpth, marker='o', label='test-accuracy',color='red')
        plt.legend(loc='best')
        plt.plot(depths, val_acc_dpth, marker='o', label='val-accuracy',color='yellow')
        plt.legend(loc='best')
        plt.xlabel('Maximum depth')
        plt.ylabel('Accuracy')
        plt.title("Accuracy vs Maximum depth")
        # plt.savefig('../plots/Q1d/dcombined_depth_accuracy.png', facecolor='w', bbox_inches='tight')
        plt.show()
    
    train_acc_trees = []
    test_acc_trees = []
    val_acc_trees = []
    #Varying num_trees for max_depth=3
    for nt in num_trees:
        decision_stumps = createEnsemble(num_estimators=nt, tree_max_depth=3)
        model_predictions_test = []
        model_predictions_train = []
        model_predictions_val = []

        #iterating over each tree in the stump and finding predictions for all samples for each stump.
        for model in decision_stumps:

            random_train_sample = (train_set.sample(frac=0.5)).copy() #randomly select 50% of training data
            x_train_subset = np.array(random_train_sample.drop(['month'], axis='columns'))
            y_train_subset = np.array(random_train_sample['month'])
            model.fit(x_train_subset, y_train_subset)

            prediction = model.predict(x_test)
            model_predictions_test.append(prediction)

            prediction_train = model.predict(x_train)
            model_predictions_train.append(prediction_train)

            prediction_val = model.predict(x_val)
            model_predictions_val.append(prediction_val)

        model_predictions_test = np.array(model_predictions_test)
        final_prediction_test = np.array(majorityVoting(model_predictions_test)) #majority voting for predicting ouput over test set
        final_test_accuracy = calculateAccuracy(final_prediction_test, y_test) #calculate accuracy over test set.
        test_acc_trees.append(final_test_accuracy)

        model_predictions_train = np.array(model_predictions_train)
        final_prediction_train = np.array(majorityVoting(model_predictions_train)) #majority voting for predicting ouput over train set
        final_train_accuracy = calculateAccuracy(final_prediction_train, y_train) #calculate accuracy over train set.
        train_acc_trees.append(final_train_accuracy)

        model_predictions_val = np.array(model_predictions_val)
        final_prediction_val = np.array(majorityVoting(model_predictions_val)) #majority voting for predicting ouput over val set
        final_val_accuracy = calculateAccuracy(final_prediction_val, y_val) #calculate accuracy over val set
        val_acc_trees.append(final_val_accuracy)
        
        print(f'Number of Trees (max_depth=3): {nt} \nTrain Accuracy: {final_train_accuracy}\nTest Accuracy: {final_test_accuracy}\nValidation Accuracy: {final_val_accuracy}\n-------------X-------------')
    #plotting accuracy vs number of trees for a fix depth
    if(plot==True):
        plt.plot(num_trees, train_acc_trees, marker='o', color='blue')
        plt.xlabel('Number of Trees (max_depth=3)')
        plt.ylabel('Train Accuracy')
        plt.title("Train accuracy vs No. of trees (max_depth=3)")
        # plt.savefig('../plots/Q1d/trees_train_accuracy.png', facecolor='w', bbox_inches='tight')
        plt.show()

        plt.plot(num_trees, test_acc_trees, marker='o', color='red')
        plt.xlabel('Number of Trees (max_depth=3)')
        plt.ylabel('Test Accuracy')
        plt.title("Test accuracy vs No. of trees (max_depth=3)")
        # plt.savefig('../plots/Q1d/trees_test_accuracy.png', facecolor='w', bbox_inches='tight')
        plt.show()

        plt.plot(num_trees, val_acc_trees, marker='o', color='yellow')
        plt.xlabel('Number of Trees (max_depth=3)')
        plt.ylabel('Validation Accuracy')
        plt.title("Validation accuracy vs No. of trees (max_depth=3)")
        # plt.savefig('../plots/Q1d/trees_val_accuracy.png', facecolor='w', bbox_inches='tight')
        plt.show()
        
        plt.plot(num_trees, train_acc_trees, marker='o', label='train-accuracy',color='blue')
        plt.legend(loc='best')
        plt.plot(num_trees, test_acc_trees, marker='o', label='test-accuracy',color='red')
        plt.legend(loc='best')
        plt.plot(num_trees, val_acc_trees, marker='o', label='val-accuracy',color='yellow')
        plt.legend(loc='best')
        plt.xlabel('Number of Trees (max_depth=3)')
        plt.ylabel('Accuracy')
        plt.title("Accuracy vs No. of trees (max_depth=3)")
        # plt.savefig('../plots/Q1d/trees_comb_accuracy.png', facecolor='w', bbox_inches='tight')
        plt.show()
    

    #Varying depth while varying number of trees
    for nt in num_trees:
        train_acc_both = []
        test_acc_both = []
        val_acc_both = []
        for dpth in depths:
            decision_stumps = createEnsemble(num_estimators=nt, tree_max_depth=dpth)
            model_predictions_test = []
            model_predictions_train = []
            model_predictions_val = []

            for model in decision_stumps:

                random_train_sample = (train_set.sample(frac=0.5)).copy()
                x_train_subset = np.array(random_train_sample.drop(['month'], axis='columns'))
                y_train_subset = np.array(random_train_sample['month'])
                model.fit(x_train_subset, y_train_subset)

                prediction = model.predict(x_test)
                model_predictions_test.append(prediction)

                prediction_train = model.predict(x_train)
                model_predictions_train.append(prediction_train)

                prediction_val = model.predict(x_val)
                model_predictions_val.append(prediction_val)

            model_predictions_test = np.array(model_predictions_test)
            final_prediction_test = np.array(majorityVoting(model_predictions_test)) #majority voting for predicting ouput over test set
            final_test_accuracy = calculateAccuracy(final_prediction_test, y_test) #accuracy over test set
            test_acc_both.append(final_test_accuracy)

            model_predictions_train = np.array(model_predictions_train)
            final_prediction_train = np.array(majorityVoting(model_predictions_train)) #majority voting for predicting ouput over train set
            final_train_accuracy = calculateAccuracy(final_prediction_train, y_train) #accuracy over train set
            train_acc_both.append(final_train_accuracy)

            model_predictions_val = np.array(model_predictions_val)
            final_prediction_val = np.array(majorityVoting(model_predictions_val)) #majority voting for predicting ouput over val set
            final_val_accuracy = calculateAccuracy(final_prediction_val, y_val) #accuracy over val set
            val_acc_both.append(final_val_accuracy)

            print(f'Max Depth (num_trees= {nt}): {dpth} \nTrain Accuracy: {final_train_accuracy}\nTest Accuracy: {final_test_accuracy}\nValidation Accuracy: {final_val_accuracy}\n-------------X-------------')
        
        #plotting the same
        if(plot==True):
            plt.plot(depths, train_acc_both, marker='o', color='blue')
            plt.xlabel(f'Max Depth for ensemble of {nt} trees')
            plt.ylabel('Train Accuracy')
            plt.title(f'Train accuracy vs Max Depth ({nt} trees)')
            # plt.savefig(f'../plots/Q1d/{nt}trees_{dpth}depth_train.png', facecolor='w', bbox_inches='tight')
            plt.show()

            plt.plot(depths, test_acc_both, marker='o', color='red')
            plt.xlabel(f'Max Depth for ensemble of {nt} trees')
            plt.ylabel('Test Accuracy')
            plt.title(f'Test accuracy vs Max Depth ({nt} trees)')
            # plt.savefig(f'../plots/Q1d/{nt}trees_{dpth}depth_test.png', facecolor='w', bbox_inches='tight')
            plt.show()

            plt.plot(depths, val_acc_both, marker='o', color='yellow')
            plt.xlabel(f'Max Depth for ensemble of {nt} trees')
            plt.ylabel('Val Accuracy')
            plt.title(f'Val accuracy vs Max Depth ({nt} trees)')
            # plt.savefig(f'../plots/Q1d/{nt}trees_{dpth}depth_val.png', facecolor='w', bbox_inches='tight')
            plt.show()
            
            plt.plot(depths, train_acc_both, marker='o', label='train-accuracy',color='blue')
            plt.legend(loc='best')
            plt.plot(depths, test_acc_both, marker='o', label='test-accuracy',color='red')
            plt.legend(loc='best')
            plt.plot(depths, val_acc_both, marker='o', label='val-accuracy',color='yellow')
            plt.legend(loc='best')
            plt.xlabel(f'Max Depth for ensemble of {nt} trees')
            plt.ylabel('Accuracy')
            plt.title(f"Accuracy vs Max Depth ({nt} trees)")
            # plt.savefig(f'../plots/Q1d/{nt}trees_{dpth}depth_comb.png', facecolor='w', bbox_inches='tight')
            plt.show()

Q1_d(train_set, train_X, train_Y, test_X, test_Y, val_X, val_Y, plot=True)

def Q1_e(train_set, x_test, y_test, plot=False):
    num_estimators = [4, 8, 10, 15, 20]
    test_acc = []
    #choosing different values for number of estimators by going through a loop
    for num_trees in num_estimators:
        adaboost_model = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=num_trees) #creaeting the AdaBoost classifier model
        random_train_sample = (train_set.sample(frac=0.5)).copy() #randomly select 50% of training data
        x_train_subset = np.array(random_train_sample.drop(['month'], axis='columns'))
        y_train_subset = np.array(random_train_sample['month'])
        adaboost_model.fit(x_train_subset, y_train_subset) #fitting the model
        test_prediction = adaboost_model.predict(x_test) #predicted output on test input
        test_accuracy = calculateAccuracy(test_prediction, y_test) #calculating accuracy
        test_acc.append(test_accuracy)
        print(f'Num estimators = {num_trees}:\nTest Accuracy: {test_accuracy}\n---------X-----------\n')
    if(plot == True):
        plt.plot(num_estimators, test_acc)
        plt.xlabel('Number of estimators')
        plt.ylabel('Test Accuracy')
        plt.title('Adaboost: Test Accuracy vs Number of Estimators')
        # plt.savefig('../plots/Q1e/accuracy_plot.png', facecolor='w', bbox_inches='tight')
        plt.show()

Q1_e(train_set, test_X, test_Y, plot=True)